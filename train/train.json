{
    "vocab_size": 10000,
    "context_length": 256,
    "d_model": 512,
    "d_ff": 1344,
    "RoPE_theta": 10000.0,
    "num_layers": 4,
    "num_heads": 16
}